
@misc{misc,
  author       = {Peter Isley}, 
  title        = {The title of the work},
  howpublished = {How it was published},
  month        = 7,
  year         = 1993,
  note         = {An optional note}
}

@misc{Leadbeater2015,
author = {Leadbeater, Charles},
journal = {Aeon},
title = {{The Disremembered}},
url = {https://aeon.co/essays/if-your-memory-fails-are-you-still-the-same-person},
year = {2015}
}


@article{Blum2014,
abstract = {The role of the hippocampus in memory is dependent on its interaction with distributed brain areas. Anterior and posterior hippocampus have different roles in memory processing, and are impacted differently by aging in terms of structural decline, however, functional connectivity of these hippocampal regions in aging is not well understood. Young (age 17–30) and aging (age 60–69) cognitively normal subjects underwent resting-state functional MRI revealing a shift from anterior hippocampus dominant hippocampus connectivity in younger age group to posterior hippocampus dominant connectivity in aging subjects. We identified a subset of neocortical regions that are connected to the anterior hippocampus in younger adults but to the posterior hippocampus among older subjects, suggesting an age-related reorganization of hippocampal networks supporting normal cognitive function. We also performed volumetric analysis which revealed no significant structural differences between groups. These findings provide evidence that “functional anatomy” which supports normal memory performance changes across the life span.},
author = {Blum, Sonja and Habeck, Christian and Steffener, Jason and Razlighi, Qolamreza and Stern, Yaakov},
doi = {10.1080/17588928.2014.975680},
issn = {17588936},
journal = {Cognitive Neuroscience},
keywords = {Hippocampus,Memory,Network},
title = {{Functional connectivity of the posterior hippocampus is more dominant as we age}},
year = {2014}
}

@inproceedings{Song2017,
abstract = {To understand how memories are encoded in the hippocampus, we build memory decoding models to classify visual memories based on hippocampal activities in human. Model inputs are spatio-temporal patterns of spikes recorded in the hippocampal CA3 and CA1 regions of epilepsy patients performing a delayed match-to-sample (DMS) task. Model outputs are binary labels indicating categories and features of sample images. To solve the super high-dimensional estimation problem with short data length, we develop a multi-trial, sparse model estimation method utilizing B-spline basis functions with a large range of temporal resolutions and a regularized logistic classifier. Results show that this model can effectively avoid overfitting and provide significant amount of prediction to memory categories and features using very limited number of data points. Stable estimation of sparse classification function matrices for each label can be obtained with this multi-resolution, multi-trial procedure. These classification models can be used not only to predict memory contents, but also to design optimal spatio-temporal patterns for eliciting specific memories in the hippocampus, and thus have important implications to the development of hippocampal memory prostheses.},
author = {Song, Dong and She, Xiwei and Hampson, Robert E. and Deadwyler, Sam A. and Berger, Theodore W.},
booktitle = {Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS},
doi = {10.1109/EMBC.2017.8037006},
isbn = {9781509028092},
issn = {1557170X},
title = {{Multi-resolution multi-trial sparse classification model for decoding visual memories from hippocampal spikes in human}},
year = {2017}
}

@book{Semon1923,
  title = {Mnemic Psychology},
  publisher = {Allen & Unwin},
  year = {1923},
  author = {Semon, Richard},
}

@article {Josselyneaaw4325,
	author = {Josselyn, Sheena A. and Tonegawa, Susumu},
	title = {Memory engrams: Recalling the past and imagining the future},
	volume = {367},
	number = {6473},
	elocation-id = {eaaw4325},
	year = {2020},
	doi = {10.1126/science.aaw4325},
	publisher = {American Association for the Advancement of Science},
	abstract = {The ability to form memory is an essential trait that allows learning and the accumulation of knowledge. But what is a memory? There has been a long history of searching for the neuronal substrate that forms memory in the brain, and the emerging view is that ensembles of engram cells explain how memories are formed and retrieved. In a Review, Josselyn and Tonegawa discuss the evidence for engram cells as a substrate of memory, particularly in rodents; what we have learned so far about the features of memory, including memory formation, retrieval over time, and loss; and future directions to understand how memory becomes knowledge.Science, this issue p. eaaw4325BACKGROUNDThe idea that memory is stored as enduring changes in the brain dates back at least to the time of Plato and Aristotle (circa 350 BCE), but its scientific articulation emerged in the 20th century when Richard Semon introduced the term {\textquotedblleft}engram{\textquotedblright} to describe the neural substrate for storing and recalling memories. Essentially, Semon proposed that an experience activates a population of neurons that undergo persistent chemical and/or physical changes to become an engram. Subsequent reactivation of the engram by cues available at the time of the experience induces memory retrieval. After Karl Lashley failed to find the engram in a rat brain, studies attempting to localize an engram were largely abandoned. Spurred by Donald O. Hebb{\textquoteright}s theory that augmented synaptic strength and neuronal connectivity are critical for memory formation, many researchers showed that enhanced synaptic strength was correlated with memory. Nonetheless, the causal relationship between these enduring changes in synaptic connectivity with a specific, behaviorally identifiable memory at the level of the cell ensemble (an engram) awaited further advances in experimental technologies.ADVANCESThe resurgence in research examining engrams may be linked to two complementary studies that applied intervention strategies to target individual neurons in an engram supporting a specific memory in mice. One study showed that ablating the subset of lateral amygdala neurons allocated to a putative engram disrupted subsequent memory retrieval (loss of function). The second study showed that artificially reactivating a subset of hippocampal dentate gyrus neurons that were active during a fearful experience (and, therefore, part of a putative engram) induced memory retrieval in the absence of external retrieval cues (gain of function). Subsequent findings from many labs used similar strategies to identify engrams in other brain regions supporting different types of memory.There are several recent advances in engram research. First, eligible neurons within a given brain region were shown to compete for allocation to an engram, and relative neuronal excitability determines the outcome of this competition. Excitability-based competition also guides the organization of multiple engrams in the brain and determines how these engrams interact. Second, research examining the nature of the off-line, enduring changes in engram cells (neurons that are critical components of an engram) found increased synaptic strength and spine density in these neurons as well as preferential connectivity to other downstream engram cells. Therefore, both increased intrinsic excitability and synaptic plasticity work hand in hand to form engrams, and these mechanisms are also implicated in memory consolidation and retrieval processes. Third, it is now possible to artificially manipulate memory encoding and retrieval processes to generate false memories, or even create a memory in mice without any natural sensory experience (implantation of a memory for an experience that did not occur). Fourth, {\textquotedblleft}silent{\textquotedblright} engrams were discovered in amnesic mice; artificial reactivation of silent engrams induces memory retrieval, whereas natural cues cannot. Endogenous engram silencing may contribute to the change in memory over time (e.g., systems memory consolidation) or in different circumstances (e.g., fear memory extinction). These findings suggest that once formed, an engram may exist in different states (from silent to active) on the basis of their retrievability. Although initial engram studies focused on single brain regions, an emerging concept is that a given memory is supported by an engram complex, composed of functionally connected engram cell ensembles dispersed across multiple brain regions, with each ensemble supporting a component of the overall memory.OUTLOOKThe ability to identify and manipulate engram cells and brainwide engram complexes has introduced an exciting new era of memory research. The findings from many labs are beginning to define an engram as the basic unit of memory. However, many questions remain. In the short term, it is critical to characterize how information is stored in an engram, including how engram architecture affects memory quality, strength, and precision; how multiple engrams interact; how engrams change over time; and the role of engram silencing in these processes. The long-term goal of engram research is to leverage the fundamental findings from rodent engram studies to understand how information is acquired, stored, and used in humans and facilitate the treatment of human memory, or other information-processing, disorders. The development of low- to noninvasive technology may enable new human therapies based on the growing knowledge of engrams in rodents.An engram cell alongside a nonengram cell.Within the hippocampus, dentate gyrus cells were filled with biocytin (white) to examine morphology. Engram cells active during context fear conditioning were engineered to express the red fluorescent protein mCherry, which appears pink owing to overlap with biocytin signals. Axons of the perforant path (green) express the excitatory opsin channelrhodopsin 2 and a fluorescent marker (enhanced yellow fluorescent protein). The upper blade of the dentate gyrus granule cell layer is revealed by the nuclear stain 4',6-diamidino-2-phenylindole (DAPI, blue).CREDIT: ADAPTED FROM T. J. RYAN ET AL., SCIENCE 348, 1007 (2015).In 1904, Richard Semon introduced the term {\textquotedblleft}engram{\textquotedblright} to describe the neural substrate for storing memories. An experience, Semon proposed, activates a subset of cells that undergo off-line, persistent chemical and/or physical changes to become an engram. Subsequent reactivation of this engram induces memory retrieval. Although Semon{\textquoteright}s contributions were largely ignored in his lifetime, new technologies that allow researchers to image and manipulate the brain at the level of individual neurons has reinvigorated engram research. We review recent progress in studying engrams, including an evaluation of evidence for the existence of engrams, the importance of intrinsic excitability and synaptic plasticity in engrams, and the lifetime of an engram. Together, these findings are beginning to define an engram as the basic unit of memory.},
	issn = {0036-8075},
	URL = {https://science.sciencemag.org/content/367/6473/eaaw4325},
	eprint = {https://science.sciencemag.org/content/367/6473/eaaw4325.full.pdf},
	journal = {Science}
}

@inproceedings{Bashivan2016,
abstract = {One of the challenges in modeling cognitive events from electroencephalogram (EEG) data is finding representations that are invariant to inter- and intra-subject differences, as well as to inherent noise associated with EEG data collection. Herein, we propose a novel approach for learning such representations from multichannel EEG time-series, and demonstrate its advantages in the context of mental load classification task. First, we transform EEG activities into a sequence of topology-preserving multi-spectral images, as opposed to standard EEG analysis techniques that ignore such spatial information. Next, we train a deep recurrent-convolutional network inspired by state-of-the-art video classification techniques to learn robust representations from the sequence of images. The proposed approach is designed to preserve the spatial, spectral, and temporal structure of EEG which leads to finding features that are less sensitive to variations and distortions within each dimension. Empirical evaluation on the cognitive load classification task demonstrated significant improvements in classification accuracy over current state-of-the-art approaches in this field.},
archivePrefix = {arXiv},
arxivId = {1511.06448},
author = {Bashivan, Pouya and Rish, Irina and Yeasin, Mohammed and Codella, Noel},
booktitle = {4th International Conference on Learning Representations, ICLR 2016 - Conference Track Proceedings},
eprint = {1511.06448},
title = {{Learning representations from EEG with deep recurrent-convolutional neural networks}},
year = {2016}
}

@article{Garcia2014,
abstract = {Neuroscientists use many different software tools to acquire, analyze and visualize electrophysiological signals. However, incompatible data models and file formats make it difficult to exchange data between these tools. This reduces scientific productivity, renders potentially useful analysis methods inaccessible and impedes collaboration between labs. A common representation of the core data would improve interoperability and facilitate data-sharing. To that end, we propose here a language-independent object model, named "Neo" suitable for representing data acquired from electroencephalographic, intracellular, or extracellular recordings, or generated from simulations. As a concrete instantiation of this object model we have developed an open source implementation in the Python programming language. In addition to representing electrophysiology data in memory for the purposes of analysis and visualization, the Python implementation provides a set of input/output(IO) modules for reading/writing the data from/to a variety of commonly used file formats. Support is included for formats produced by most of the major manufacturers of electrophysiology recording equipment and also for more generic formats such as MATLAB. Data representation and data analysis are conceptually separate: it is easier to write robust analysis code if it is focused on analysis and relies on an underlying package to handle data representation. For that reason, and also to be as lightweight as possible, the Neo object model and the associated Python package are deliberately limited to representation of data, with no functions for data analysis or visualization. Software for neurophysiology data analysis and visualization built on top of Neo automatically gains the benefits of interoperability, easier data sharing and automatic format conversion; there is already a burgeoning ecosystem of such tools. We intend that Neo should become the standard basis for Python tools in neurophysiology. {\textcopyright} 2014 Garcia, Guarino, Jaillet, Jennings, Propper, Rautenberg, Rodgers, Sobolev, Wachtler, Yger and Davison.},
author = {Garcia, Samuel and Guarino, Domenico and Jaillet, Florent and Jennings, Todd and Pr{\"{o}}pper, Robert and Rautenberg, Philipp L. and Rodgers, Chris C. and Sobolev, Andrey and Wachtler, Thomas and Yger, Pierre and Davison, Andrew P.},
doi = {10.3389/fninf.2014.00010},
issn = {16625196},
journal = {Frontiers in Neuroinformatics},
keywords = {Electrophysiology,File formats,Interoperability,Python,Software},
title = {{Neo: An object model for handling electrophysiology data in multiple formats}},
year = {2014}
}

@article{Gagnon2018,
author = {Gagnon, G. and Kumar, S. and Maltais, J. R. and Voineskos, A. N. and Mulsant, B. H. and Rajji, T. K.},
doi = {10.1016/j.scog.2018.06.001},
issn = {22150013},
journal = {Schizophrenia Research: Cognition},
title = {{Superior memory performance in healthy individuals with subclinical psychotic symptoms but without genetic load for schizophrenia}},
year = {2018}
}
@article{Waskom2017,
abstract = {Many decisions require a context-dependent mapping from sensory evidence to action. The capacity for flexible information processing of this sort is thought to depend on a cognitive control system in frontoparietal cortex, but the costs and limitations of control entail that its engagement should be minimized. Here, we show that humans reduce demands on control by exploiting statistical structure in their environment. Using a context-dependent perceptual discrimination task and model-based analyses of behavioral and neuroimaging data, we found that predictions about task context facilitated decision making and that a quantitative measure of context prediction error accounted for graded engagement of the frontoparietal control network. Within this network, multivariate analyses further showed that context prediction error enhanced the representation of task context. These results indicate that decision making is adaptively tuned by experience to minimize costs while maintaining flexibility.},
author = {Waskom, Michael L. and Frank, Michael C. and Wagner, Anthony D.},
doi = {10.1093/cercor/bhv333},
issn = {14602199},
journal = {Cerebral cortex (New York, N.Y. : 1991)},
keywords = {fMRI,learning,parietal cortex,prediction error,prefrontal cortex},
title = {{Adaptive Engagement of Cognitive Control in Context-Dependent Decision Making}},
year = {2017}
}

@article{Berger2001,
author = {Berger, T W and Baudry, M and Brinton, R D and Liaw, J S and Marmarelis, V Z and Park, A Y},
file = {:Users/garrettflynn/Library/Application Support/Mendeley Desktop/Downloaded/Berger et al. - 2001 - Brain-implantable biomimetic electronics as the next era in neural prosthetics. Proceedings of the.pdf:pdf},
journal = {Ieee},
keywords = {biomimetic signal processing,hippocampus,mixed,multisite electrode array,neural engineering,neural net-,neural prosthetic,neuron-silicon interface,pattern recogni-,signal,work},
number = {7},
pages = {993--1012},
title = {{Brain-implantable biomimetic electronics as the next era in neural prosthetics. Proceedings of the}},
volume = {89},
year = {2001}
}
